{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris.data)\n",
    "df.columns = [\"sl\", \"sw\", 'pl', 'pw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find label for a value\n",
    "#if MIN_Value <=val < (m + Mean_Value) / 2 then it is assigned label a\n",
    "#if (m + Mean_Value) <=val < Mean_Value then it is assigned label b\n",
    "#if (Mean_Value) <=val < (Mean_Value + MAX_Value)/2 then it is assigned label c\n",
    "#if (Mean_Value + MAX_Value)/2 <=val <= MAX_Value  then it is assigned label d\n",
    "\n",
    "def label(val, *boundaries):\n",
    "    if (val < boundaries[0]):\n",
    "        return 'a'\n",
    "    elif (val < boundaries[1]):\n",
    "        return 'b'\n",
    "    elif (val < boundaries[2]):\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'd'\n",
    "\n",
    "#Function to convert a continuous data into labelled data\n",
    "#There are 4 lables  - a, b, c, d\n",
    "def toLabel(df, old_feature_name):\n",
    "    second = df[old_feature_name].mean()\n",
    "    minimum = df[old_feature_name].min()\n",
    "    first = (minimum + second)/2\n",
    "    maximum = df[old_feature_name].max()\n",
    "    third = (maximum + second)/2\n",
    "    return df[old_feature_name].apply(label, args= (first, second, third))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>sl_labeled</th>\n",
       "      <th>sw_labeled</th>\n",
       "      <th>pl_labeled</th>\n",
       "      <th>pw_labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sl   sw   pl   pw sl_labeled sw_labeled pl_labeled pw_labeled\n",
       "0    5.1  3.5  1.4  0.2          b          c          a          a\n",
       "1    4.9  3.0  1.4  0.2          a          b          a          a\n",
       "2    4.7  3.2  1.3  0.2          a          c          a          a\n",
       "3    4.6  3.1  1.5  0.2          a          c          a          a\n",
       "4    5.0  3.6  1.4  0.2          a          c          a          a\n",
       "5    5.4  3.9  1.7  0.4          b          d          a          a\n",
       "6    4.6  3.4  1.4  0.3          a          c          a          a\n",
       "7    5.0  3.4  1.5  0.2          a          c          a          a\n",
       "8    4.4  2.9  1.4  0.2          a          b          a          a\n",
       "9    4.9  3.1  1.5  0.1          a          c          a          a\n",
       "10   5.4  3.7  1.5  0.2          b          c          a          a\n",
       "11   4.8  3.4  1.6  0.2          a          c          a          a\n",
       "12   4.8  3.0  1.4  0.1          a          b          a          a\n",
       "13   4.3  3.0  1.1  0.1          a          b          a          a\n",
       "14   5.8  4.0  1.2  0.2          b          d          a          a\n",
       "15   5.7  4.4  1.5  0.4          b          d          a          a\n",
       "16   5.4  3.9  1.3  0.4          b          d          a          a\n",
       "17   5.1  3.5  1.4  0.3          b          c          a          a\n",
       "18   5.7  3.8  1.7  0.3          b          d          a          a\n",
       "19   5.1  3.8  1.5  0.3          b          d          a          a\n",
       "20   5.4  3.4  1.7  0.2          b          c          a          a\n",
       "21   5.1  3.7  1.5  0.4          b          c          a          a\n",
       "22   4.6  3.6  1.0  0.2          a          c          a          a\n",
       "23   5.1  3.3  1.7  0.5          b          c          a          a\n",
       "24   4.8  3.4  1.9  0.2          a          c          a          a\n",
       "25   5.0  3.0  1.6  0.2          a          b          a          a\n",
       "26   5.0  3.4  1.6  0.4          a          c          a          a\n",
       "27   5.2  3.5  1.5  0.2          b          c          a          a\n",
       "28   5.2  3.4  1.4  0.2          b          c          a          a\n",
       "29   4.7  3.2  1.6  0.2          a          c          a          a\n",
       "..   ...  ...  ...  ...        ...        ...        ...        ...\n",
       "120  6.9  3.2  5.7  2.3          d          c          d          d\n",
       "121  5.6  2.8  4.9  2.0          b          b          c          d\n",
       "122  7.7  2.8  6.7  2.0          d          b          d          d\n",
       "123  6.3  2.7  4.9  1.8          c          b          c          c\n",
       "124  6.7  3.3  5.7  2.1          c          c          d          d\n",
       "125  7.2  3.2  6.0  1.8          d          c          d          c\n",
       "126  6.2  2.8  4.8  1.8          c          b          c          c\n",
       "127  6.1  3.0  4.9  1.8          c          b          c          c\n",
       "128  6.4  2.8  5.6  2.1          c          b          d          d\n",
       "129  7.2  3.0  5.8  1.6          d          b          d          c\n",
       "130  7.4  2.8  6.1  1.9          d          b          d          d\n",
       "131  7.9  3.8  6.4  2.0          d          d          d          d\n",
       "132  6.4  2.8  5.6  2.2          c          b          d          d\n",
       "133  6.3  2.8  5.1  1.5          c          b          c          c\n",
       "134  6.1  2.6  5.6  1.4          c          b          d          c\n",
       "135  7.7  3.0  6.1  2.3          d          b          d          d\n",
       "136  6.3  3.4  5.6  2.4          c          c          d          d\n",
       "137  6.4  3.1  5.5  1.8          c          c          d          c\n",
       "138  6.0  3.0  4.8  1.8          c          b          c          c\n",
       "139  6.9  3.1  5.4  2.1          d          c          d          d\n",
       "140  6.7  3.1  5.6  2.4          c          c          d          d\n",
       "141  6.9  3.1  5.1  2.3          d          c          c          d\n",
       "142  5.8  2.7  5.1  1.9          b          b          c          d\n",
       "143  6.8  3.2  5.9  2.3          c          c          d          d\n",
       "144  6.7  3.3  5.7  2.5          c          c          d          d\n",
       "145  6.7  3.0  5.2  2.3          c          b          c          d\n",
       "146  6.3  2.5  5.0  1.9          c          a          c          d\n",
       "147  6.5  3.0  5.2  2.0          c          b          c          d\n",
       "148  6.2  3.4  5.4  2.3          c          c          d          d\n",
       "149  5.9  3.0  5.1  1.8          c          b          c          c\n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert all columns to labelled data\n",
    "df['sl_labeled'] = toLabel(df, 'sl')\n",
    "df['sw_labeled'] = toLabel(df, 'sw')\n",
    "df['pl_labeled'] = toLabel(df, 'pl')\n",
    "df['pw_labeled'] = toLabel(df, 'pw') \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['sl', 'sw', 'pl', 'pw'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'c', 'd'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['sl_labeled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y']=((iris.target)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted the dataframe to list as I work good lists\n",
    "\n",
    "df=((df.to_numpy()).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(df,iris.target,random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column labels.\n",
    "# These are used only to print the steps and tree.\n",
    "header=['sl_labeled','sw_labeled','pl_labeled','pw_labeled','y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_vals(rows, col):\n",
    "    ## Find the unique values for a column in a dataset.\n",
    "    \n",
    "    return set([row[col] for row in rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(rows):\n",
    "    ## Counts the number of each type of example in a dataset.\n",
    "    \n",
    "    counts = {}  # a dictionary of label -> count.\n",
    "    for row in rows:\n",
    "        # in our dataset format, the label is always the last column\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    \"\"\"\n",
    "    A Question is used to partition the dataset.\n",
    "    This class just records a 'column number' and a 'column value' .\n",
    "    The 'match' method is used to compare\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "    def match(self, example):\n",
    "        # Compare the feature value in an example to the\n",
    "        # feature value in this question.\n",
    "        val = example[self.column]\n",
    "        return val == self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        return \"Is %s %s %s?\" % (\n",
    "            header[self.column], condition, str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(rows, question):\n",
    "    \"\"\"Partitions the dataset based on the question.\n",
    "\n",
    "    For each row in the dataset, check if it matches the question. If\n",
    "    so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
    "    \"\"\"\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "    ## Calculate the Gini Index for a list of rows.\n",
    "\n",
    "    counts = class_counts(rows)\n",
    "    index = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        index -= prob_of_lbl**2\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_gain(left, right, current_gini):\n",
    "    ## Gain in gini index after split.\n",
    "    \n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_gini - p * gini(left) - (1 - p) * gini(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    \"\"\"Find the best question to ask by iterating over every feature / value\n",
    "    and calculating the gain in gini.\"\"\"\n",
    "    best_gain = 0  # keep track of the best gain\n",
    "    best_question = None  # keep track of the feature / value that produced it\n",
    "    current_gini = gini(rows)\n",
    "    n_features = len(rows[0]) - 1  # number of columns\n",
    "\n",
    "    for col in range(n_features):  # for each feature\n",
    "\n",
    "        values = set([row[col] for row in rows])  # unique values in the column\n",
    "\n",
    "        for val in values:  # for each value\n",
    "\n",
    "            question = Question(col, val)\n",
    "\n",
    "            # try splitting the dataset\n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "            # Skip this split if it doesn't divide the dataset.\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate the information gain from this split\n",
    "            gain = gini_gain(true_rows, false_rows, current_gini)\n",
    "            \n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "\n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \"\"\"Leaf node - classify data.\n",
    "\n",
    "    This holds a dictionary of class -> number of times\n",
    "    it appears in the rows from the training data that reach this leaf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rows):\n",
    "        d = class_counts(rows)\n",
    "        D={}\n",
    "        if 0 in d:\n",
    "           D['setosa']=d[0]\n",
    "        if 1 in d:\n",
    "           D['versicolor']=d[1]\n",
    "        if 2 in d:\n",
    "           D['virginica']=d[2]\n",
    "        ## this dictionary holds the count in a leaf node\n",
    "        self.predictions=D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    \"\"\"Decision Node - asks a question.\n",
    "\n",
    "    This holds a reference to the question, and to the two child nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 question,\n",
    "                 true_branch,\n",
    "                 false_branch,\n",
    "                 gain_list,\n",
    "                 rows):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        self.gain_list = gain_list\n",
    "        d = class_counts(rows)\n",
    "        D={}\n",
    "        if 0 in d:\n",
    "           D['setosa']=d[0]\n",
    "        if 1 in d:\n",
    "           D['versicolor']=d[1]\n",
    "        if 2 in d:\n",
    "           D['virginica']=d[2]\n",
    "        ## this dictionary holds the count in a non-leaf node\n",
    "        self.predictions=D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows,gain_list=[]):\n",
    "    ## Builds the tree.\n",
    "\n",
    "\n",
    "    # Try partitioing the dataset on each of the unique attribute,\n",
    "    # calculate the gain,\n",
    "    # and return the question that produces the highest gain.\n",
    "    gain, question = find_best_split(rows)\n",
    "    # Base case: no further gain\n",
    "    # Since we can ask no further questions,\n",
    "    # we'll return a leaf.\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "    # If we reach here, we have found a useful feature / value\n",
    "    # to partition on.\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "    \n",
    "    \n",
    "    # Recursively build the true branch.\n",
    "    true_branch = build_tree(true_rows,gain_list)\n",
    "\n",
    "    # Recursively build the false branch.\n",
    "    false_branch = build_tree(false_rows,gain_list)\n",
    "\n",
    "    # Return a Question node.\n",
    "    # This records the best feature / value to ask at this point,\n",
    "    # as well as the branches to follow\n",
    "    # dependingo on the answer.\n",
    "    gain_list.append(gain)\n",
    "    return Decision_Node(question, true_branch, false_branch,gain_list,rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_steps(node,i):\n",
    "    ## tree printing function.\n",
    "    \n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        print (\"Count\", node.predictions)\n",
    "        print (\"Reached leaf node\")\n",
    "        return\n",
    "    else:\n",
    "        print (\"Count\", node.predictions)\n",
    "\n",
    "    # Print the question at this node\n",
    "    print ('\\nlevel : %d'%(i))\n",
    "    print ('The best feature to split on with gain ratio %f is:'%(node.gain_list[i]))\n",
    "    print ( str(node.question))\n",
    "    \n",
    "    i=i+1\n",
    "    # Call this function recursively on the true branch\n",
    "    print ('--> True:')\n",
    "    print_steps(node.true_branch,i)\n",
    "\n",
    "    # Call this function recursively on the false branch\n",
    "    print ('--> False:')\n",
    "    print_steps(node.false_branch,i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "\n",
    "    # Base case: reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "\n",
    "    # Decide whether to follow the true-branch or the false-branch.\n",
    "    # Compare the feature / value stored in the node\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_leaf(counts):\n",
    "    \"\"\"A nicer way to print the predictions at a leaf,\n",
    "       by converting it to percentage.\"\"\"\n",
    "    total = sum(counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys():\n",
    "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    ## tree printing function.\n",
    "\n",
    "    # Base case: reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        print (spacing + \"Count\", node.predictions)\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        print (spacing + \"Count\", node.predictions)\n",
    "    # Print the question at this node\n",
    "    print (spacing + str(node.question))\n",
    "\n",
    "    # Call this function recursively on the true branch\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Call this function recursively on the false branch\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing if the functions work properly\n",
    "# unique_vals(data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing if the functions work properly\n",
    "\n",
    "# class_counts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing if the functions work properly\n",
    "\n",
    "# q=Question(2,'a')\n",
    "# print(q)\n",
    "# true_rows, false_rows = partition(data[40:60], q)\n",
    "# print('\\nTrue-',true_rows,'\\n\\nFalse-', false_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing if the functions work properly\n",
    "\n",
    "# current_gini=gini(data)\n",
    "# gini_gain(true_rows, false_rows, current_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing if the functions work properly\n",
    "\n",
    "# best_gain, best_question = find_best_split(data)\n",
    "# best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count {'setosa': 34, 'versicolor': 39, 'virginica': 39}\n",
      "\n",
      "level : 0\n",
      "The best feature to split on with gain ratio 0.000659 is:\n",
      "Is pw_labeled == a?\n",
      "--> True:\n",
      "Count {'setosa': 34}\n",
      "Reached leaf node\n",
      "--> False:\n",
      "Count {'versicolor': 39, 'virginica': 39}\n",
      "\n",
      "level : 1\n",
      "The best feature to split on with gain ratio 0.052288 is:\n",
      "Is pw_labeled == d?\n",
      "--> True:\n",
      "Count {'virginica': 28}\n",
      "Reached leaf node\n",
      "--> False:\n",
      "Count {'versicolor': 39, 'virginica': 11}\n",
      "\n",
      "level : 2\n",
      "The best feature to split on with gain ratio 0.033058 is:\n",
      "Is pl_labeled == d?\n",
      "--> True:\n",
      "Count {'virginica': 5}\n",
      "Reached leaf node\n",
      "--> False:\n",
      "Count {'versicolor': 39, 'virginica': 6}\n",
      "\n",
      "level : 3\n",
      "The best feature to split on with gain ratio 0.027240 is:\n",
      "Is sl_labeled == b?\n",
      "--> True:\n",
      "Count {'versicolor': 16}\n",
      "Reached leaf node\n",
      "--> False:\n",
      "Count {'versicolor': 23, 'virginica': 6}\n",
      "\n",
      "level : 4\n",
      "The best feature to split on with gain ratio 0.019617 is:\n",
      "Is sw_labeled == c?\n",
      "--> True:\n",
      "Count {'versicolor': 7}\n",
      "Reached leaf node\n",
      "--> False:\n",
      "Count {'versicolor': 16, 'virginica': 6}\n",
      "\n",
      "level : 5\n",
      "The best feature to split on with gain ratio 0.135200 is:\n",
      "Is pw_labeled == b?\n",
      "--> True:\n",
      "Count {'versicolor': 4}\n",
      "Reached leaf node\n",
      "--> False:\n",
      "Count {'versicolor': 12, 'virginica': 6}\n",
      "\n",
      "level : 6\n",
      "The best feature to split on with gain ratio 0.280000 is:\n",
      "Is sl_labeled == c?\n",
      "--> True:\n",
      "Count {'versicolor': 12, 'virginica': 5}\n",
      "\n",
      "level : 7\n",
      "The best feature to split on with gain ratio 0.317124 is:\n",
      "Is sw_labeled == a?\n",
      "--> True:\n",
      "Count {'versicolor': 2, 'virginica': 1}\n",
      "Reached leaf node\n",
      "--> False:\n",
      "Count {'versicolor': 10, 'virginica': 4}\n",
      "Reached leaf node\n",
      "--> False:\n",
      "Count {'virginica': 1}\n",
      "Reached leaf node\n"
     ]
    }
   ],
   "source": [
    "# Building tree and printing the steps:\n",
    "\n",
    "my_tree = build_tree(data)\n",
    "print_steps(my_tree,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'versicolor': '66%', 'virginica': '33%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '66%', 'virginica': '33%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '66%', 'virginica': '33%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "\n",
      "\n",
      "\n",
      "confusion matrix of training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            true  false\n",
       "setosa        34      0\n",
       "versicolor    39      0\n",
       "virginica     34      5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    checking the prediction on training data\n",
    "    printing actual type and prediction for checking\n",
    "    and confusion matrix\n",
    "\"\"\"\n",
    "d={0:0,1:0,2:0}\n",
    "t1=0;t2=0;t3=0;f1=0;f2=0;f3=0;\n",
    "y_pred_train=[]\n",
    "for row in data:\n",
    "    D=print_leaf(classify(row, my_tree))\n",
    "    l=list(D.keys())\n",
    "    predicted_label=l[0]\n",
    "    y_pred_train.append(row[-1])\n",
    "    if row[-1]==0:\n",
    "        label='setosa'\n",
    "        if predicted_label==label:\n",
    "            t1+=1\n",
    "        else:\n",
    "            f1+=1\n",
    "    if row[-1]==1:\n",
    "        label='versicolor'\n",
    "        if predicted_label==label:\n",
    "            t2+=1\n",
    "        else:\n",
    "            f2+=1\n",
    "    if row[-1]==2:\n",
    "        label='virginica'\n",
    "        if predicted_label==label:\n",
    "            t3+=1\n",
    "        else:\n",
    "            f3+=1\n",
    "    print (\"Actual: %s - Predicted: %s\" %\n",
    "           (label, D))\n",
    "\n",
    "\n",
    "data1=np.array([[t1,f1],[t2,f2],[t3,f3]])\n",
    "index=[\"setosa\",\"versicolor\",\"virginica\"]\n",
    "conf_mat= pd.DataFrame({'true':data1[:,0],'false':data1[:,1]},index=index)\n",
    "print('\\n\\n')\n",
    "print('confusion matrix of training data:')\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '66%', 'virginica': '33%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: virginica - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '100%'}\n",
      "Actual: setosa - Predicted: {'setosa': '100%'}\n",
      "Actual: virginica - Predicted: {'virginica': '100%'}\n",
      "Actual: versicolor - Predicted: {'versicolor': '71%', 'virginica': '28%'}\n",
      "\n",
      "\n",
      "\n",
      "confusion matrix of testing data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            true  false\n",
       "setosa        16      0\n",
       "versicolor    11      0\n",
       "virginica      9      2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    checking the prediction on testing data\n",
    "    printing actual type and prediction for checking\n",
    "    and confusion matrix\n",
    "\"\"\"\n",
    "d={0:0,1:0,2:0}\n",
    "t1=0;t2=0;t3=0;f1=0;f2=0;f3=0;\n",
    "y_pred_test=[]\n",
    "for row in x_test:\n",
    "    D=print_leaf(classify(row, my_tree))\n",
    "    l=list(D.keys())\n",
    "    predicted_label=l[0]\n",
    "    y_pred_test.append( )\n",
    "    if row[-1]==0:\n",
    "        label='setosa'\n",
    "        if predicted_label==label:\n",
    "            t1+=1\n",
    "        else:\n",
    "            f1+=1\n",
    "    if row[-1]==1:\n",
    "        label='versicolor'\n",
    "        if predicted_label==label:\n",
    "            t2+=1\n",
    "        else:\n",
    "            f2+=1\n",
    "    if row[-1]==2:\n",
    "        label='virginica'\n",
    "        if predicted_label==label:\n",
    "            t3+=1\n",
    "        else:\n",
    "            f3+=1\n",
    "    print (\"Actual: %s - Predicted: %s\" %\n",
    "           (label, D))\n",
    "\n",
    "\n",
    "data1=np.array([[t1,f1],[t2,f2],[t3,f3]])\n",
    "index=[\"setosa\",\"versicolor\",\"virginica\"]\n",
    "conf_mat= pd.DataFrame({'true':data1[:,0],'false':data1[:,1]},index=index)\n",
    "print('\\n\\n')\n",
    "print('confusion matrix of testing data:')\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "[[16  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "train classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       1.00      1.00      1.00        39\n",
      "           2       1.00      1.00      1.00        39\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       112\n",
      "   macro avg       1.00      1.00      1.00       112\n",
      "weighted avg       1.00      1.00      1.00       112\n",
      "\n",
      "[[34  0  0]\n",
      " [ 0 39  0]\n",
      " [ 0  0 39]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('\\ntest classification_report:')\n",
    "print(classification_report(y_test,np.array(y_pred_test)))\n",
    "print(confusion_matrix(y_test,np.array(y_pred_test)))\n",
    "print('\\ntrain classification_report:')\n",
    "print(classification_report(y_train,np.array(y_pred_train)))\n",
    "print(confusion_matrix(y_train,np.array(y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count {'setosa': 34, 'versicolor': 39, 'virginica': 39}\n",
      "Is pw_labeled == a?\n",
      "--> True:\n",
      "  Count {'setosa': 34}\n",
      "--> False:\n",
      "  Count {'versicolor': 39, 'virginica': 39}\n",
      "  Is pw_labeled == d?\n",
      "  --> True:\n",
      "    Count {'virginica': 28}\n",
      "  --> False:\n",
      "    Count {'versicolor': 39, 'virginica': 11}\n",
      "    Is pl_labeled == d?\n",
      "    --> True:\n",
      "      Count {'virginica': 5}\n",
      "    --> False:\n",
      "      Count {'versicolor': 39, 'virginica': 6}\n",
      "      Is sl_labeled == b?\n",
      "      --> True:\n",
      "        Count {'versicolor': 16}\n",
      "      --> False:\n",
      "        Count {'versicolor': 23, 'virginica': 6}\n",
      "        Is sw_labeled == c?\n",
      "        --> True:\n",
      "          Count {'versicolor': 7}\n",
      "        --> False:\n",
      "          Count {'versicolor': 16, 'virginica': 6}\n",
      "          Is pw_labeled == b?\n",
      "          --> True:\n",
      "            Count {'versicolor': 4}\n",
      "          --> False:\n",
      "            Count {'versicolor': 12, 'virginica': 6}\n",
      "            Is sl_labeled == c?\n",
      "            --> True:\n",
      "              Count {'versicolor': 12, 'virginica': 5}\n",
      "              Is sw_labeled == a?\n",
      "              --> True:\n",
      "                Count {'versicolor': 2, 'virginica': 1}\n",
      "              --> False:\n",
      "                Count {'versicolor': 10, 'virginica': 4}\n",
      "            --> False:\n",
      "              Count {'virginica': 1}\n"
     ]
    }
   ],
   "source": [
    "## printing the tree\n",
    "\n",
    "print_tree(my_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
